# Whether to use GPU
use_gpu: True
seed: 0
# Deciding which GPU to use
device: 2

results_DIR: 'results'
response_DIR: 'exp'

# Federate learning related options
federate:
  # `standalone` or `distributed`
  mode: 'standalone'
  # Evaluate in Server or Client test set
  make_global_eval: True
  # Number of dataset being split
  client_num: 10
  # Number of communication round
  total_round_num: 100
  method: 'darts'


# Dataset related options
data:
  # Root directory where the data stored
  root: data/
  # Dataset name
  type: pubmed
  # Use Louvain algorithm to split `Cora`
  splitter: 'louvain'
  dgl: False
  mode: 'unify_data'


dataloader:
  # Type of sampler
  type: pyg
  # Use fullbatch training, batch_size should be `1`
  batch_size: 20
#  num_neigh: -1

# Model related options
model:
  # Model type
  type: fl-darts
  # Hidden dim
  hidden: 32
  # Dropout rate
  dropout: 0.7
  layer: 1
  struct: '0122'
  operations: 'daeb' # len must be 4
  actions: 'a'
  # Number of Class of `Cora`
#  num_classes: 7

graphnas:
  save_epoch: 2
  max_save_num: 5
  controller:
    layers_of_child_model: 2
    shared_initial_step: 0
    entropy_mode: 'reward'
    entropy_coeff: 1e-4
    shared_rnn_max_length: 35
    search_mode: 'macro'
    format: 'two'
    max_epoch: 10
    ema_baseline_decay: 0.95
    discount: 1.0
    controller_max_step: 100
    controller_optim: 'adam'
    controller_lr: 3.5e-4
    controller_grad_clip: 0.0
    tanh_c: 2.5
    softmax_temperature: 5.0
    derive_num_sample: 100
    derive_finally: True
    derive_from_history: True
  child:
    retrain_epochs: 300
    residual: 'store_false'
    indrop: 0.6
    lr: 0.005
    param_file: "cora_test.pkl"
    optim_file: "opt_cora_test.pkl"
    max_param: 5e6
    supervised: False
    submanager_log_file: f"sub_manager_logger_file_{time.time()}.txt"

    
# Criterion related options
criterion:
  # Criterion type
  type: CrossEntropyLoss

# Trainer related options
trainer:
  # Trainer type
#  type: nodefullbatch_trainer
  type: fedDarts

# Train related options
train:
  # Number of local update steps
  local_update_steps: 4
  # Optimizer related options
  optimizer:
    # Learning rate
    lr: 0.001
    # Weight decay
    weight_decay: 5e-6
    # Optimizer type
    type: Adam #SGD

# Evaluation related options
eval:
  # Frequency of evaluation
  freq: 10  #----------------------------------------------------------------
  # Evaluation metrics, accuracy and number of correct items
  metrics: ['roc_auc','acc']
  best_res_update_round_wise_key: test_acc
  split: ['test']
